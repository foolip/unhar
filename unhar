#!/usr/bin/env python3
#
# Unpacks a raw httparchive har file into one file per resource.

import gzip
import json
import os
import sys

def unhar(path):
    openfunc = gzip.open if path.endswith('.gz') else open
    with openfunc(path, mode='rt', encoding='utf-8', errors='ignore') as f:
        data = json.load(f, strict=False)

    basepath = path
    while True:
        base, ext = os.path.splitext(basepath)
        if ext in ['.har', '.gz']:
            basepath = base
        else:
            break

    page = None
    for (index, entry) in enumerate(data['log']['entries']):
        url = entry['request']['url']
        if index == 0:
            page = url

        try:
            text = entry['response']['content']['text']
        except:
            continue

        outpath = '%s.%d.txt' % (basepath, index)
        with open(outpath, mode='wt', encoding='utf-8', errors='ignore') as f:
            f.write('page: %s\n' % page)
            f.write('url: %s\n' % url)
            f.write('\n')
            f.write(text)

if __name__ == '__main__':
    for path in sys.argv[1:]:
        try:
            unhar(path)
        except:
            print('Failed to extract ' + path)
